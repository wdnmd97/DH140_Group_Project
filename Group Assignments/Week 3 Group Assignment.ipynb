{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset\n",
    "\n",
    "* Since this Pfizer Vaccine Tweets dataset is continually updating, we want to pull the dataset directly from Kaggle using the provided API.\n",
    "* To use the Kaggle API, you need to do the following:\n",
    "    * Go to your account, Scroll to API section and Click Expire API Token to remove previous tokens.\n",
    "    * Click on Create New API Token - It will download kaggle.json file on your machine.\n",
    "    * now just put it in the location¬†C:\\Users\\(your user name)\\.kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (1.5.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (2.24.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (1.25.11)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from kaggle) (4.50.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files('gpreda/pfizer-vaccine-tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the dataset you just download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile('pfizer-vaccine-tweets.zip')\n",
    "#extracted data is saved in the same directory as notebook\n",
    "zf.extractall() \n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import nessasery tools like Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and check variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'retweets', 'favorites',\n",
      "       'is_retweet'],\n",
      "      dtype='object')\n",
      "(4487, 16)\n"
     ]
    }
   ],
   "source": [
    "df_tweets = pd.read_csv('vaccination_tweets.csv')\n",
    "print(df_tweets.columns)\n",
    "print(df_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "Now we drop the columns that we will not use for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_name', 'user_location', 'user_created', 'user_followers',\n",
       "       'user_friends', 'user_favourites', 'user_verified', 'date', 'text',\n",
       "       'source', 'retweets', 'favorites', 'is_retweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.drop(columns=['user_description','hashtags'], inplace=True)\n",
    "df_tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting user's locations.\n",
    "We extract the cities first, if it is provided.\n",
    "To accomplish this task, we will us a  library call Geotext.\n",
    "This library allow us to extract city name and country code without going through the NLP hassle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geotext in c:\\users\\wuyue\\anaconda3\\lib\\site-packages (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geotext\n",
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['London']\n",
      "GB\n",
      "tada!\n"
     ]
    }
   ],
   "source": [
    "# must import this method to extract keys from ordered dictionary\n",
    "from collections import OrderedDict \n",
    "places1 = GeoText(\"my bed\")\n",
    "print(places1.cities)\n",
    "# prints empty list []\n",
    "places2 = GeoText(\"London is a great city\")\n",
    "print(places2.cities)\n",
    "# prints ['London']\n",
    "print(list(places2.country_mentions.keys())[0])\n",
    "print(\"tada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['a', 'b', 'c', 'd'])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict \n",
    "od = OrderedDict() \n",
    "od['a'] = 1\n",
    "od['b'] = 2\n",
    "od['c'] = 3\n",
    "od['d'] = 4\n",
    "print(od.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should drop the rows that user_location is not string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3574, 14)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_drop = []\n",
    "for index, row in df_tweets.iterrows():\n",
    "    if type(row['user_location']) is not str:\n",
    "        indexes_to_drop.append(df_tweets.index[index])\n",
    "    \n",
    "df_tweets.drop(indexes_to_drop, inplace=True)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost about 900 data points, but we still have about 3500 left.\n",
    "Nowe we extract and assign the city names to the each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>user_city</th>\n",
       "      <th>user_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Montrose</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1337852648389832708</td>\n",
       "      <td>Dee</td>\n",
       "      <td>Birmingham, England</td>\n",
       "      <td>2020-01-26 21:43:12</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:11:42</td>\n",
       "      <td>Does anyone have any useful advice/guidance fo...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>1350785637201403907</td>\n",
       "      <td>Dee</td>\n",
       "      <td>Birmingham, England</td>\n",
       "      <td>2020-01-26 21:43:12</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-17 12:42:46</td>\n",
       "      <td>Breastfeeding 2 week old but with guidelines r...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>1350779065406468099</td>\n",
       "      <td>Saju Mathew MD MPH</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>2018-08-12 20:43:47</td>\n",
       "      <td>900</td>\n",
       "      <td>309</td>\n",
       "      <td>1482</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-17 12:16:40</td>\n",
       "      <td>Shot #2.  Done.  Thanks.   #PfizerBioNTech.  \\...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>1350774240572801025</td>\n",
       "      <td>Dr.Altaf Dashti</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>2011-03-13 21:10:54</td>\n",
       "      <td>1498</td>\n",
       "      <td>691</td>\n",
       "      <td>19321</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-17 11:57:29</td>\n",
       "      <td>System has been activated and updated ü§™ ‚úåüèº\\n\\n...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>1350772172273430528</td>\n",
       "      <td>Patricia Hamila</td>\n",
       "      <td>Nice, France</td>\n",
       "      <td>2015-10-03 05:59:58</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>1010</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-17 11:49:16</td>\n",
       "      <td>My parents will be getting their first #COVID1...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Nice</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>1350767903482646530</td>\n",
       "      <td>TheLiveMirror</td>\n",
       "      <td>India</td>\n",
       "      <td>2018-05-30 12:37:32</td>\n",
       "      <td>147</td>\n",
       "      <td>692</td>\n",
       "      <td>224</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-01-17 11:32:18</td>\n",
       "      <td>29 Dead In Norway After Getting Vaccinated Wit...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3574 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id           user_name              user_location  \\\n",
       "0     1340539111971516416          Rachel Roh  La Crescenta-Montrose, CA   \n",
       "1     1338158543359250433         Albert Fong          San Francisco, CA   \n",
       "2     1337858199140118533            eliüá±üáπüá™üá∫üëå                   Your Bed   \n",
       "3     1337855739918835717       Charles Adler     Vancouver, BC - Canada   \n",
       "5     1337852648389832708                 Dee        Birmingham, England   \n",
       "...                   ...                 ...                        ...   \n",
       "4481  1350785637201403907                 Dee        Birmingham, England   \n",
       "4482  1350779065406468099  Saju Mathew MD MPH                Atlanta, GA   \n",
       "4484  1350774240572801025     Dr.Altaf Dashti                     Kuwait   \n",
       "4485  1350772172273430528     Patricia Hamila               Nice, France   \n",
       "4486  1350767903482646530       TheLiveMirror                      India   \n",
       "\n",
       "             user_created  user_followers  user_friends  user_favourites  \\\n",
       "0     2009-04-08 17:52:46             405          1692             3247   \n",
       "1     2009-09-21 15:27:30             834           666              178   \n",
       "2     2020-06-25 23:30:28              10            88              155   \n",
       "3     2008-09-10 11:28:53           49165          3933            21853   \n",
       "5     2020-01-26 21:43:12             105           108              106   \n",
       "...                   ...             ...           ...              ...   \n",
       "4481  2020-01-26 21:43:12             112           112              119   \n",
       "4482  2018-08-12 20:43:47             900           309             1482   \n",
       "4484  2011-03-13 21:10:54            1498           691            19321   \n",
       "4485  2015-10-03 05:59:58              21           320             1010   \n",
       "4486  2018-05-30 12:37:32             147           692              224   \n",
       "\n",
       "      user_verified                 date  \\\n",
       "0             False  2020-12-20 06:06:44   \n",
       "1             False  2020-12-13 16:27:13   \n",
       "2             False  2020-12-12 20:33:45   \n",
       "3              True  2020-12-12 20:23:59   \n",
       "5             False  2020-12-12 20:11:42   \n",
       "...             ...                  ...   \n",
       "4481          False  2021-01-17 12:42:46   \n",
       "4482          False  2021-01-17 12:16:40   \n",
       "4484          False  2021-01-17 11:57:29   \n",
       "4485          False  2021-01-17 11:49:16   \n",
       "4486          False  2021-01-17 11:32:18   \n",
       "\n",
       "                                                   text               source  \\\n",
       "0     Same folks said daikon paste could treat a cyt...  Twitter for Android   \n",
       "1     While the world has been on the wrong side of ...      Twitter Web App   \n",
       "2     #coronavirus #SputnikV #AstraZeneca #PfizerBio...  Twitter for Android   \n",
       "3     Facts are immutable, Senator, even when you're...      Twitter Web App   \n",
       "5     Does anyone have any useful advice/guidance fo...   Twitter for iPhone   \n",
       "...                                                 ...                  ...   \n",
       "4481  Breastfeeding 2 week old but with guidelines r...   Twitter for iPhone   \n",
       "4482  Shot #2.  Done.  Thanks.   #PfizerBioNTech.  \\...   Twitter for iPhone   \n",
       "4484  System has been activated and updated ü§™ ‚úåüèº\\n\\n...   Twitter for iPhone   \n",
       "4485  My parents will be getting their first #COVID1...  Twitter for Android   \n",
       "4486  29 Dead In Norway After Getting Vaccinated Wit...            TweetDeck   \n",
       "\n",
       "      retweets  favorites  is_retweet      user_city user_country  \n",
       "0            0          0       False       Montrose           US  \n",
       "1            1          1       False  San Francisco           US  \n",
       "2            0          0       False                              \n",
       "3          446       2129       False      Vancouver           CA  \n",
       "5            0          0       False     Birmingham           US  \n",
       "...        ...        ...         ...            ...          ...  \n",
       "4481         1         15       False     Birmingham           US  \n",
       "4482         3         42       False        Atlanta           US  \n",
       "4484         1         12       False                              \n",
       "4485         0          0       False           Nice           FR  \n",
       "4486         1          0       False                              \n",
       "\n",
       "[3574 rows x 16 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict \n",
    "user_city = []\n",
    "user_country = []\n",
    "for index, row in df_tweets.iterrows():\n",
    "    #df_tweets.index[index]['user_city'] = GeoText(row['user_location'])\n",
    "    if GeoText(row['user_location']).cities:\n",
    "        user_city.append(GeoText(row['user_location']).cities[0])\n",
    "        user_country.append(list(GeoText(row['user_location']).country_mentions.keys())[0])\n",
    "    else:\n",
    "        user_city.append('')\n",
    "        user_country.append('')\n",
    "    #if GeoText(row['user_location']).cities:\n",
    "    #    row['user_city'] = GeoText(row['user_location']).cities[0]\n",
    "    #print(GeoText(row['user_location']).cities)\n",
    "\n",
    "df_tweets['user_city'] = user_city\n",
    "df_tweets['user_country'] = user_country\n",
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dubai</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Delhi</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mumbai</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watford</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cornwall</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_city\n",
       "                1769\n",
       "London           167\n",
       "Dubai             59\n",
       "New York          50\n",
       "New Delhi         46\n",
       "Toronto           40\n",
       "Mumbai            39\n",
       "Watford           37\n",
       "Glasgow           37\n",
       "Cornwall          35"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['user_city'].value_counts().to_frame().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZA</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_country\n",
       "            1769\n",
       "US           710\n",
       "GB           391\n",
       "IN           161\n",
       "CA           145\n",
       "AE            67\n",
       "DE            32\n",
       "IE            30\n",
       "ZA            24\n",
       "PH            22"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['user_country'].value_counts().to_frame().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait, could a user tweet multiple times?\n",
    "<br /> Let's find out if there is any user that tweets a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ian 3.5% #FBPE</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whtrslugcaviiersong#dontstayhomeandcatchcovid19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simon Hodes ‚¨ÖÔ∏è2m‚û°Ô∏è üò∑</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRag</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ILKHA</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Khaleej Times</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Straits Times</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>üï∑Financial Bear 3.5%</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sue Reeve ‚ô•Ô∏èüß°üíõüíöüíôüíúüá™üá∫üá™üá∫üè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gulf News</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Peninsula Qatar</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tamer Yazar</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ÿ≠ÿ≥ŸÜ ÿ≥ÿ¨ŸàÿßŸÜŸä üá¶üá™ Hassan Sajwani</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Financial Mirror</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kambiz mahmoudpour - ŸÖÿ≥ŸàŸÑ ÿßŸÜÿ¨ŸÖŸÜ ÿ¢ÿ≤ÿßÿØ€å ÿßÿØ€åÿßŸÜ</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_name  count\n",
       "0                                    Ian 3.5% #FBPE     33\n",
       "1   Whtrslugcaviiersong#dontstayhomeandcatchcovid19     30\n",
       "2                              Simon Hodes ‚¨ÖÔ∏è2m‚û°Ô∏è üò∑     30\n",
       "3                                            TheRag     29\n",
       "4                                             ILKHA     29\n",
       "5                                     Khaleej Times     27\n",
       "6                                 New Straits Times     25\n",
       "7                              üï∑Financial Bear 3.5%     25\n",
       "8                     Sue Reeve ‚ô•Ô∏èüß°üíõüíöüíôüíúüá™üá∫üá™üá∫üè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåà     20\n",
       "9                                         Gulf News     16\n",
       "10                              The Peninsula Qatar     16\n",
       "11                                      Tamer Yazar     13\n",
       "12                     ÿ≠ÿ≥ŸÜ ÿ≥ÿ¨ŸàÿßŸÜŸä üá¶üá™ Hassan Sajwani     13\n",
       "13                                 Financial Mirror     12\n",
       "14      kambiz mahmoudpour - ŸÖÿ≥ŸàŸÑ ÿßŸÜÿ¨ŸÖŸÜ ÿ¢ÿ≤ÿßÿØ€å ÿßÿØ€åÿßŸÜ     12"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_tweeters = df_tweets['user_name'].value_counts().head(15).to_frame().reset_index()\n",
    "frequent_tweeters.columns = ['user_name', 'count']\n",
    "frequent_tweeters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find out where are these user tweeting from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country  city    \n",
       "AE       Dubai       13\n",
       "CA       Cornwall    33\n",
       "GB       Watford     30\n",
       "         Glasgow     20\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = []\n",
    "countries = []\n",
    "for index, row in df_tweets.iterrows():\n",
    "    #df_tweets.index[index]['user_city'] = GeoText(row['user_location'])\n",
    "    if row['user_name'] in list(frequent_tweeters['user_name']):\n",
    "        if row['user_city'] and row['user_country']:\n",
    "            cities.append(row['user_city'])\n",
    "            countries.append(row['user_country'])\n",
    "pairs = {'city': cities , 'country': countries}\n",
    "df = pd.DataFrame(pairs)\n",
    "df.groupby('country')['city'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see these users contributed the majority of tweets from Cornwall Watford and Glasgow. we may study more closely what are they tweeting later, but for now we will exclude these cities from our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
